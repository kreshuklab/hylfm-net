{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Dict, Sequence\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "# import napari\n",
    "import seaborn\n",
    "import torch\n",
    "from imageio import imread\n",
    "from ruamel.yaml import YAML\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hylfm.eval.metrics import compute_metrics_individually, init_metrics\n",
    "yaml = YAML(typ=\"safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validate_df(name, step_dirs, z_mod):\n",
    "    metrics_config = yaml.load(Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/configs/metrics/heart_dynamic.yml\"))\n",
    "    metrics_instances = init_metrics(metrics_config)\n",
    "\n",
    "    all_preds = []\n",
    "    all_ls_slices = []\n",
    "    pred_nrs = []\n",
    "    for step_dir in tqdm(step_dirs, desc=f\"load raw data for {name}\"):\n",
    "        assert step_dir.name == \"run000\"\n",
    "        pred_nr = int(step_dir.parent.name.split(\"_\")[-1])\n",
    "        pred_nrs.append(pred_nr)\n",
    "        ls_slices = numpy.stack([imread(p) for p in sorted(step_dir.glob(\"ds0-0/ls_slice/*.tif\"))])\n",
    "        assert (ls_slices.shape[0] % z_mod) == 0\n",
    "        all_ls_slices.append(ls_slices)\n",
    "        preds = numpy.stack([imread(p) for p in sorted(step_dir.glob(\"ds0-0/pred/*.tif\"))])\n",
    "        assert preds.shape == ls_slices.shape, (preds.shape, ls_slices.shape)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    data = None\n",
    "    for pred_nr, preds, ls_slices in tqdm(zip(pred_nrs, all_preds, all_ls_slices), total=len(all_preds), desc=f\"comp. metrics for {name}\"):\n",
    "        step = 0\n",
    "        for idx, (pred, ls_slice) in enumerate(zip(preds, ls_slices)):\n",
    "            # add batch and channel dim\n",
    "            pred = pred[None, None]\n",
    "            ls_slice = ls_slice[None, None]\n",
    "\n",
    "            tensors = {\"pred\": torch.from_numpy(pred), \"ls_slice\": torch.from_numpy(ls_slice)}\n",
    "            computed_metrics = {k: m.value for k, m in compute_metrics_individually(metrics_instances, tensors).items()}\n",
    "            computed_metrics[\"idx\"] = idx\n",
    "            computed_metrics[\"pred_nr\"] = pred_nr\n",
    "            if data is None:\n",
    "                data = {k: [v] for k, v in computed_metrics.items()}\n",
    "            else:\n",
    "                for mk, mv in computed_metrics.items():\n",
    "                    data[mk].append(mv)\n",
    "\n",
    "    df = pandas.DataFrame.from_dict(data)\n",
    "    df[\"swipe_through\"] = df[\"pred_nr\"]\n",
    "    df[\"pred_nr\"] = 0\n",
    "    return df\n",
    "\n",
    "def get_refine_ls_slices(z_mod, fish2: bool):\n",
    "    if fish2:\n",
    "#         ls_dir = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/validate_fish2/from_static_heart/20-11-12_15-11-48/test_dynamic_00/run000\")\n",
    "        ls_dir = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/validate_fish2/from_static_heart/20-11-13_14-25-29/test_dynamic_00/run000\")\n",
    "    else:\n",
    "        ls_dir = Path(\n",
    "            \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/train/heart/z_out49/dualview_single_lfm_static_f4_center49/20-11-09_18-09-02/validate_train_01/run000\"\n",
    "        )\n",
    "\n",
    "    ls_slices = numpy.stack([imread(p) for p in sorted(ls_dir.glob(\"ds0-0/ls_slice/*.tif\"))])\n",
    "    assert (ls_slices.shape[0] % z_mod) == 0, (ls_slices.shape[0], z_mod)\n",
    "    return ls_slices\n",
    "\n",
    "\n",
    "\n",
    "def get_refine_df(name, step_dirs, z_mod, ls_slices):\n",
    "    assert (ls_slices.shape[0] % z_mod) == 0, (ls_slices.shape[0], z_mod)\n",
    "\n",
    "    metrics_config = yaml.load(Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/configs/metrics/heart_dynamic.yml\"))\n",
    "    metrics_instances = init_metrics(metrics_config)\n",
    "\n",
    "    all_preds = []\n",
    "    pred_nrs = []\n",
    "    for step_dir in tqdm(step_dirs, desc=f\"load raw data for ls_slices\"):\n",
    "        assert step_dir.name.startswith(\"run\")\n",
    "        pred_nr = int(step_dir.name.replace(\"run\", \"\"))\n",
    "        pred_nrs.append(pred_nr)\n",
    "\n",
    "        preds = numpy.stack([imread(p) for p in sorted(step_dir.glob(\"ds0-0/pred/*.tif\"))])\n",
    "        assert preds.shape == ls_slices.shape, (preds.shape, ls_slices.shape)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    data = None\n",
    "    for pred_nr, preds in zip(tqdm(pred_nrs, desc=f\"comp. metrics for {name}\"), all_preds):\n",
    "        for idx, (pred, ls_slice) in enumerate(zip(preds, ls_slices)):\n",
    "            # add batch and channel dim\n",
    "            pred = pred[None, None]\n",
    "            ls_slice = ls_slice[None, None]\n",
    "\n",
    "            tensors = {\"pred\": torch.from_numpy(pred), \"ls_slice\": torch.from_numpy(ls_slice)}\n",
    "            computed_metrics = {k: m.value for k, m in compute_metrics_individually(metrics_instances, tensors).items()}\n",
    "            computed_metrics[\"idx\"] = idx\n",
    "            computed_metrics[\"pred_nr\"] = pred_nr\n",
    "            if data is None:\n",
    "                data = {k: [v] for k, v in computed_metrics.items()}\n",
    "            else:\n",
    "                for mk, mv in computed_metrics.items():\n",
    "                    data[mk].append(mv)\n",
    "\n",
    "    df = pandas.DataFrame.from_dict(data)\n",
    "    df[\"swipe_through\"] = df[\"idx\"] // z_mod\n",
    "    return df\n",
    "\n",
    "def get_df(name, *, pred_nrs = (0,), ls_slices: Dict[int, numpy.ndarray]):\n",
    "    if name == \"validate_from_static_heart\":\n",
    "        root = Path(\n",
    "            # \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/z_out49/contin_validate_f4/20-11-10_14-02-53\"\n",
    "            \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/z_out49/contin_validate_f4/20-11-11_19-35-43\"\n",
    "#             \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/z_out49/contin_validate_f4/20-11-13_13-53-21\" ??\n",
    "        )\n",
    "\n",
    "        assert root.exists(), root\n",
    "        z_min = 29\n",
    "        z_mod = 189\n",
    "        step_dirs = sorted(root.glob(\"test_dynamic_*/run000\"))\n",
    "    elif name == \"validate_fish2/from_static_heart\":\n",
    "        # /g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/validate_fish2/from_static_heart/20-11-12_15-11-48\n",
    "        root = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/validate_fish2/from_static_heart/20-11-13_14-25-29\")\n",
    "        z_min = 19\n",
    "        z_mod = 209\n",
    "        step_dirs = [root / \"test_dynamic_00/run000\"]\n",
    "    elif name.startswith(\"refine_fish2/\"):\n",
    "        map_name_here = name[len(\"refine_fish2/\"):]\n",
    "        z_min = 29\n",
    "        z_mod = 189\n",
    "        common_root = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/train/heart/\")\n",
    "        names_map = {}\n",
    "        times_map = {\n",
    "            \"from_bad_static_heart\": \"20-11-12_15-45-00\",\n",
    "            # \"from_heart_lr\": \"20-11-12_15-42-08\",\n",
    "            \"from_heart_lr\": \"20-11-12_17-08-03\",\n",
    "            # \"from_medium_beads\": \"20-11-12_15-42-08\",\n",
    "            \"from_medium_beads\": \"20-11-12_17-08-03\",\n",
    "            # \"from_mednlarge_beads\": \"20-11-12_15-15-55\",\n",
    "            # \"from_mednlarge_beads\": \"20-11-12_15-40-40\",\n",
    "            \"from_mednlarge_beads\": \"20-11-12_17-07-40\",\n",
    "            # \"from_static_heart\": \"20-11-12_15-42-07\",\n",
    "            \"from_static_heart\": \"20-11-12_17-08-02\",\n",
    "         }\n",
    "        root = common_root / names_map.get(map_name_here, name) / times_map[map_name_here]\n",
    "        assert root.exists(), root\n",
    "        step_dirs = sorted(root.glob(\"validate_train_01/run*\"))[:-1]\n",
    "    elif name.startswith(\"refine_from\"):\n",
    "        z_min = 29\n",
    "        z_mod = 189\n",
    "        common_root = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/train/heart/z_out49/\")\n",
    "        names_map = {\"refine_from_lfd_heart\": \"dualview_single_lfm_static_f4_center49\"}\n",
    "        times_map = {\n",
    "            \"refine_from_bad_static_heart\": \"20-11-11_20-00-16\",\n",
    "            \"refine_from_lfd_heart\": \"20-11-09_18-09-02\",\n",
    "            \"refine_from_medium_beads\": \"20-11-11_13-09-30\",\n",
    "            \"refine_from_mednlarge_beads\": \"20-11-11_19-55-02\",\n",
    "            \"refine_from_static_heart\": \"20-11-11_19-48-09\",\n",
    "        }\n",
    "        root = common_root / names_map.get(name, name) / times_map[name]\n",
    "        assert root.exists(), root\n",
    "        step_dirs = sorted(root.glob(\"validate_train_01/run*\"))[:-1]\n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    if name.startswith(\"validate_from\"):\n",
    "        # if \"from_static\" in name:\n",
    "        #     def idx2z(idx):\n",
    "        #         return z_min + (idx % z_mod)\n",
    "        # else:\n",
    "        #     raise NotImplementedError(name)\n",
    "        _get_df = get_validate_df\n",
    "#         step_dirs = step_dirs[:4]\n",
    "        get_df_kwargs = {}\n",
    "    elif name.startswith(\"refine\") or name.startswith(\"validate_fish2\"):\n",
    "        _get_df = get_refine_df\n",
    "        step_dirs = numpy.asarray(step_dirs)[pred_nrs]\n",
    "\n",
    "        if (z_mod, \"fish2\" in name) not in ls_slices:\n",
    "            ls_slices[z_mod] = get_refine_ls_slices(z_mod, \"fish2\" in name)\n",
    "\n",
    "        get_df_kwargs = {\"ls_slices\": ls_slices[z_mod]}\n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    def idx2z(idx):\n",
    "        return z_min + z_mod - 1 - (idx % z_mod)\n",
    "\n",
    "    df = _get_df(name, step_dirs, z_mod, **get_df_kwargs)\n",
    "    df[\"z\"] = df[\"idx\"].apply(idx2z) - 120\n",
    "    df[\"frame\"] = df[\"swipe_through\"] * 241 + 120 - df[\"z\"]\n",
    "    df[\"time [s]\"] = df[\"frame\"] * 0.025\n",
    "    df[\"run_name\"] = name\n",
    "    return df\n",
    "\n",
    "def add_df(df, name, pred_nrs, ls_slices):\n",
    "    dfs = [df, get_df(name, pred_nrs=pred_nrs, ls_slices=ls_slices)]\n",
    "    return pandas.concat(dfs)\n",
    "\n",
    "def get_dfs(*names, pred_nrs):\n",
    "    dfs = []\n",
    "    ls_slices = {}\n",
    "    for name in names:\n",
    "        dfs.append(get_df(name, pred_nrs=pred_nrs, ls_slices=ls_slices))\n",
    "\n",
    "    return pandas.concat(dfs), ls_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df, validate_ls_slices = get_dfs(\"validate_fish2/from_static_heart\", pred_nrs=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_validate_df = validate_df \n",
    "# filtered_validate_df = validate_df[(validate_df.z <= 98) & (validate_df.z >= -85)]\n",
    "filtered_validate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conti_vali(metric: str):\n",
    "    seaborn.set_style(\"whitegrid\")#, {\"axes.facecolor\": \".8\"})\n",
    "    seaborn.set_context(\"talk\")  # paper, notebook, talk, poster\n",
    "    cmap_name = \"viridis\"  # viridis, magma, cividis, plasma\n",
    "    g = seaborn.relplot(\n",
    "        x=\"time [s]\",\n",
    "        y=metric,\n",
    "        hue=\"z\",\n",
    "        legend=False,  # False, \"brief\", \"full\"\n",
    "#         row=\"pred_nr\",\n",
    "#         col=\"swipe_through\",\n",
    "#         palette=cmap_name,\n",
    "#         palette = [\"#FFB000\"], # [(1., 176/255, 0.)],   #FFB000, #FE6100, #DC267F, #785EF0 #648FFF\n",
    "        palette = cmap_name,\n",
    "        height=4, aspect=7,\n",
    "        kind=\"scatter\",\n",
    "        data=filtered_validate_df,\n",
    "    )\n",
    "#     g.map(plt.axvline, x=25, color=\".7\", dashes=(2, 1), zorder=0)\n",
    "    g.set_axis_labels(\"time [s]\", \"MS-SSIM\")\n",
    "#     g.set_titles(\"training step: {row_name}\")\n",
    "#     ax = g.axes[0][0]\n",
    "#     y_twin = ax.twiny()\n",
    "#     y_twin.set_xlim(ax.get_ylim())\n",
    "# #         y_twin.set_xticklabels(np.round(ax.get_xticks()/scale,1))\n",
    "#     y_twin.set_xlabel('z')\n",
    "    # g.add_legend()\n",
    "    \n",
    "    cbar = g.fig.colorbar(\n",
    "      matplotlib.cm.ScalarMappable(matplotlib.colors.Normalize(vmin=filtered_validate_df[\"z\"].min(), vmax=filtered_validate_df[\"z\"].max(), clip=False), cmap=cmap_name), label='z [μm]',\n",
    "#       ticks=[filtered_validate_df.z.min(), -50, 0, 50, filtered_validate_df.z.max()]\n",
    "    )\n",
    "#     cbar.ax.set_yticklabels(['< -1', '0', '> 1'])\n",
    "    #         ax.set_xlim([-z_range_value * 1.1, z_range_value * 1.1])\n",
    "#         ax.set_ylim([-z_range_value * 1.1, z_range_value * 1.1])\n",
    "#         ax.plot(ax.get_xlim(), ax.get_ylim(), ls=\"--\", c=\".3\")\n",
    "#     g.fig.colorbar(matplotlib.cm.ScalarMappable(matplotlib.colors.Normalize(vmin=z_offset, vmax=df[\"z\"].max()+z_offset, clip=False), cmap=cmap_name), label='z')\n",
    "    g.fig.axes[0].set_xlim(0, 12291*0.025)\n",
    "#     g.fig.axes[0].set_xlim(-100, 100)\n",
    "    g.fig.tight_layout()\n",
    "    root = Path(\"plot_conti_vali\")\n",
    "    root.mkdir(exist_ok=True)\n",
    "    g.fig.savefig(root / f\"{metric}.svg\")\n",
    "\n",
    "plot_conti_vali(\"ms_ssim-scaled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
