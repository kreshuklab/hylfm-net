{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Dict, Sequence\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "# import napari\n",
    "import seaborn\n",
    "import torch\n",
    "from imageio import imread\n",
    "from ruamel.yaml import YAML\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hylfm.eval.metrics import compute_metrics_individually, init_metrics\n",
    "yaml = YAML(typ=\"safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validate_df(name, step_dirs, z_mod):\n",
    "    metrics_config = yaml.load(Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/configs/metrics/heart_dynamic.yml\"))\n",
    "    metrics_instances = init_metrics(metrics_config)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_ls_slices = []\n",
    "    pred_nrs = []\n",
    "    for step_dir in tqdm(step_dirs, desc=f\"load raw data for {name}\"):\n",
    "        assert step_dir.name == \"run000\"\n",
    "        pred_nr = int(step_dir.parent.name.split(\"_\")[-1])\n",
    "        pred_nrs.append(pred_nr)\n",
    "        ls_slices = numpy.stack([imread(p) for p in sorted(step_dir.glob(\"ds0-0/ls_slice/*.tif\"))])\n",
    "        assert (ls_slices.shape[0] % z_mod) == 0\n",
    "        all_ls_slices.append(ls_slices)\n",
    "        preds = numpy.stack([imread(p) for p in sorted(step_dir.glob(\"ds0-0/pred/*.tif\"))])\n",
    "        assert preds.shape == ls_slices.shape, (preds.shape, ls_slices.shape)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    data = None\n",
    "    for pred_nr, preds, ls_slices in tqdm(zip(pred_nrs, all_preds, all_ls_slices), total=len(all_preds), desc=f\"comp. metrics for {name}\"):\n",
    "        step = 0\n",
    "        for idx, (pred, ls_slice) in enumerate(zip(preds, ls_slices)):\n",
    "            # add batch and channel dim\n",
    "            pred = pred[None, None]\n",
    "            ls_slice = ls_slice[None, None]\n",
    "\n",
    "            tensors = {\"pred\": torch.from_numpy(pred), \"ls_slice\": torch.from_numpy(ls_slice)}\n",
    "            computed_metrics = {k: m.value for k, m in compute_metrics_individually(metrics_instances, tensors).items()}\n",
    "            computed_metrics[\"idx\"] = idx\n",
    "            computed_metrics[\"pred_nr\"] = pred_nr\n",
    "            if data is None:\n",
    "                data = {k: [v] for k, v in computed_metrics.items()}\n",
    "            else:\n",
    "                for mk, mv in computed_metrics.items():\n",
    "                    data[mk].append(mv)\n",
    "\n",
    "    df = pandas.DataFrame.from_dict(data)\n",
    "    df[\"swipe_through\"] = df[\"pred_nr\"]\n",
    "    df[\"pred_nr\"] = 0\n",
    "    return df\n",
    "\n",
    "def get_refine_ls_slices(z_mod, fish2: bool):\n",
    "    if fish2:\n",
    "        ls_dir = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/validate_fish2/from_static_heart/20-11-12_15-11-48/test_dynamic_00/run000\")\n",
    "    else:\n",
    "        ls_dir = Path(\n",
    "            \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/train/heart/z_out49/dualview_single_lfm_static_f4_center49/20-11-09_18-09-02/validate_train_01/run000\"\n",
    "        )\n",
    "\n",
    "    ls_slices = numpy.stack([imread(p) for p in sorted(ls_dir.glob(\"ds0-0/ls_slice/*.tif\"))])\n",
    "    assert (ls_slices.shape[0] % z_mod) == 0, (ls_slices.shape[0], z_mod)\n",
    "    return ls_slices\n",
    "\n",
    "\n",
    "\n",
    "def get_refine_df(name, step_dirs, z_mod, ls_slices):\n",
    "    assert (ls_slices.shape[0] % z_mod) == 0, (ls_slices.shape[0], z_mod)\n",
    "\n",
    "    metrics_config = yaml.load(Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/configs/metrics/heart_dynamic.yml\"))\n",
    "    metrics_instances = init_metrics(metrics_config)\n",
    "\n",
    "    all_preds = []\n",
    "    pred_nrs = []\n",
    "    for step_dir in tqdm(step_dirs, desc=f\"load raw data for ls_slices\"):\n",
    "        assert step_dir.name.startswith(\"run\")\n",
    "        pred_nr = int(step_dir.name.replace(\"run\", \"\"))\n",
    "        pred_nrs.append(pred_nr)\n",
    "\n",
    "        preds = numpy.stack([imread(p) for p in sorted(step_dir.glob(\"ds0-0/pred/*.tif\"))])\n",
    "        assert preds.shape == ls_slices.shape, (preds.shape, ls_slices.shape)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    data = None\n",
    "    for pred_nr, preds in zip(tqdm(pred_nrs, desc=f\"comp. metrics for {name}\"), all_preds):\n",
    "        for idx, (pred, ls_slice) in enumerate(zip(preds, ls_slices)):\n",
    "            # add batch and channel dim\n",
    "            pred = pred[None, None]\n",
    "            ls_slice = ls_slice[None, None]\n",
    "\n",
    "            tensors = {\"pred\": torch.from_numpy(pred), \"ls_slice\": torch.from_numpy(ls_slice)}\n",
    "            computed_metrics = {k: m.value for k, m in compute_metrics_individually(metrics_instances, tensors).items()}\n",
    "            computed_metrics[\"idx\"] = idx\n",
    "            computed_metrics[\"pred_nr\"] = pred_nr\n",
    "            if data is None:\n",
    "                data = {k: [v] for k, v in computed_metrics.items()}\n",
    "            else:\n",
    "                for mk, mv in computed_metrics.items():\n",
    "                    data[mk].append(mv)\n",
    "\n",
    "    df = pandas.DataFrame.from_dict(data)\n",
    "    df[\"swipe_through\"] = df[\"idx\"] // z_mod\n",
    "    return df\n",
    "\n",
    "def get_df(name, *, pred_nrs = (0,), ls_slices: Dict[int, numpy.ndarray]):\n",
    "    if name == \"validate_from_static_heart\":\n",
    "        root = Path(\n",
    "            # \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/z_out49/contin_validate_f4/20-11-10_14-02-53\"\n",
    "            \"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/z_out49/contin_validate_f4/20-11-11_19-35-43\"\n",
    "        )\n",
    "\n",
    "        assert root.exists(), root\n",
    "        z_min = 29\n",
    "        z_mod = 189\n",
    "        step_dirs = sorted(root.glob(\"test_dynamic_*/run000\"))\n",
    "    elif name == \"validate_fish2/from_static_heart\":\n",
    "        root = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/test/heart/validate_fish2/from_static_heart/20-11-12_15-11-48\")\n",
    "        z_min = 29\n",
    "        z_mod = 189\n",
    "        step_dirs = [root / \"test_dynamic_00/run000\"]\n",
    "    elif name.startswith(\"refine_from\"):\n",
    "        z_min = 29\n",
    "        z_mod = 189\n",
    "        common_root = Path(\"/g/kreshuk/beuttenm/pycharm_tmp/repos/hylfm-net/logs/train/heart/z_out49/\")\n",
    "        names_map = {\"refine_from_lfd_heart\": \"dualview_single_lfm_static_f4_center49\"}\n",
    "        times_map = {\n",
    "            \"refine_from_bad_static_heart\": \"20-11-11_20-00-16\",\n",
    "            \"refine_from_lfd_heart\": \"20-11-09_18-09-02\",\n",
    "            \"refine_from_medium_beads\": \"20-11-11_13-09-30\",\n",
    "            \"refine_from_mednlarge_beads\": \"20-11-11_19-55-02\",\n",
    "            \"refine_from_static_heart\": \"20-11-11_19-48-09\",\n",
    "        }\n",
    "        root = common_root / names_map.get(name, name) / times_map[name]\n",
    "        assert root.exists(), root\n",
    "        step_dirs = sorted(root.glob(\"validate_train_01/run*\"))[:-1]\n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    if name.startswith(\"validate_from\"):\n",
    "        # if \"from_static\" in name:\n",
    "        #     def idx2z(idx):\n",
    "        #         return z_min + (idx % z_mod)\n",
    "        # else:\n",
    "        #     raise NotImplementedError(name)\n",
    "        _get_df = get_validate_df\n",
    "        step_dirs = step_dirs[:4]\n",
    "        get_df_kwargs = {}\n",
    "    elif name.startswith(\"refine\") or name.startswith(\"validate_fish2\"):\n",
    "        _get_df = get_refine_df\n",
    "        step_dirs = numpy.asarray(step_dirs)[pred_nrs]\n",
    "\n",
    "        if (z_mod, \"fish2\" in name) not in ls_slices:\n",
    "            ls_slices[z_mod] = get_refine_ls_slices(z_mod, \"fish2\" in name)\n",
    "\n",
    "        get_df_kwargs = {\"ls_slices\": ls_slices[z_mod]}\n",
    "    else:\n",
    "        raise NotImplemented(name)\n",
    "\n",
    "    def idx2z(idx):\n",
    "        return z_min + z_mod - 1 - (idx % z_mod)\n",
    "\n",
    "    df = _get_df(name, step_dirs, z_mod, **get_df_kwargs)\n",
    "    df[\"z\"] = df[\"idx\"].apply(idx2z) - 120\n",
    "    df[\"frame\"] = df[\"swipe_through\"] * 241 + 241 - df[\"z\"]\n",
    "    df[\"time [s]\"] = df[\"frame\"] * 0.025\n",
    "    df[\"run_name\"] = name\n",
    "    return df\n",
    "\n",
    "def add_df(df, ls_slices):\n",
    "    dfs = [df]\n",
    "    for name in names:\n",
    "        dfs.append(get_df(name, pred_nrs=pred_nrs, ls_slices=ls_slices))\n",
    "\n",
    "    return pandas.concat(dfs)\n",
    "\n",
    "def get_dfs(*names, pred_nrs):\n",
    "    dfs = []\n",
    "    ls_slices = {}\n",
    "    for name in names:\n",
    "        dfs.append(get_df(name, pred_nrs=pred_nrs, ls_slices=ls_slices))\n",
    "\n",
    "    return pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dfs(\"validate_fish2/from_static_heart\", pred_nrs=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = get_dfs(\"validate_from_static_heart\", \"refine_from_static_heart\", pred_nrs=[0])\n",
    "df[\"network\"] = df.run_name\n",
    "mask = df.pred_nr >= 0\n",
    "df.loc[mask, \"network\"] = df[mask].apply(lambda row: f\"refinement step: {row.pred_nr}\", axis=1)\n",
    "\n",
    "# df = get_dfs(\"validate_from_static_heart\", pred_nrs=[0,35])\n",
    "# df = get_dfs(\"refine_from_lfd_heart\", pred_nrs=[0,35])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = get_dfs(\"refine_from_bad_static_heart\", \"refine_from_static_heart\", \"refine_from_lfd_heart\", \"refine_from_mednlarge_beads\", \"refine_from_medium_beads\", pred_nrs=[0, 1, 10, 98])\n",
    "df[\"network\"] = df.run_name\n",
    "mask = df.pred_nr >= 0\n",
    "df.loc[mask, \"network\"] = df[mask].apply(lambda row: f\"refinement step: {row.pred_nr}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbins = 8\n",
    "# df['z_bin'] = pandas.cut(df['z'], bins=nbins, labels=numpy.arange(nbins))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df\n",
    "# df_filtered = df[df.pred_nr < 5]\n",
    "df_filtered.z.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_scans_grid(metric: str):\n",
    "    seaborn.set_style(\"darkgrid\", {\"axes.facecolor\": \".8\"})\n",
    "    seaborn.set_context(\"talk\")  # paper, notebook, talk, poster\n",
    "    cmap_name = \"viridis\"\n",
    "    g = seaborn.relplot(\n",
    "        x=\"z\",\n",
    "        y=metric,\n",
    "        hue=\"run_name\",\n",
    "        legend=\"brief\",  # brief, full\n",
    "        row=\"pred_nr\",\n",
    "        col=\"swipe_through\",\n",
    "#         palette=cmap_name,\n",
    "        height=4, aspect=2,\n",
    "        kind=\"scatter\",\n",
    "        data=df_filtered\n",
    "    )\n",
    "    g.map(plt.axvline, x=25, color=\".7\", dashes=(2, 1), zorder=0).set_axis_labels(\"z [Î¼m]\", \"MS-SSIM\").set_titles(\"train step: {row_name} | Swipe-through {col_name}\")#.tight_layout(w_pad=0)\n",
    "    # g.add_legend()\n",
    "#     for ax in g.axes:\n",
    "#         g.fig.colorbar(matplotlib.cm.ScalarMappable(matplotlib.colors.Normalize(vmin=z_offset, vmax=df[\"z\"].max()+z_offset, clip=False), cmap=cmap_name), label='z', ax=ax)\n",
    "#         ax.set_xlim([-z_range_value * 1.1, z_range_value * 1.1])\n",
    "#         ax.set_ylim([-z_range_value * 1.1, z_range_value * 1.1])\n",
    "#         ax.plot(ax.get_xlim(), ax.get_ylim(), ls=\"--\", c=\".3\")\n",
    "#     g.fig.colorbar(matplotlib.cm.ScalarMappable(matplotlib.colors.Normalize(vmin=z_offset, vmax=df[\"z\"].max()+z_offset, clip=False), cmap=cmap_name), label='z')\n",
    "#     g.fig.axes[0].set_xlim(0, 9399*0.025)\n",
    "    g.fig.tight_layout()\n",
    "    root = Path(\"refine_lfd_training_plots\")\n",
    "    root.mkdir(exist_ok=True)\n",
    "    g.fig.savefig(root / f\"{metric}.png\")\n",
    "    \n",
    "plot_scans_grid(\"ms_ssim-scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_scans_grid(\"ms_ssim-scaled\")\n",
    "plot_scans_grid(\"ssim-scaled\")\n",
    "plot_scans_grid(\"nrmse-scaled\")\n",
    "plot_scans_grid(\"psnr-scaled\")\n",
    "plot_scans_grid(\"mse_loss-scaled\")\n",
    "plot_scans_grid(\"smooth_l1_loss-scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_scans(metric: str):\n",
    "#     seaborn.set_style(\"darkgrid\", {\"axes.facecolor\": \".8\"})\n",
    "#     seaborn.set_context(\"talk\")  # paper, notebook, talk, poster\n",
    "#     cmap_name = \"viridis\"\n",
    "#     g = seaborn.relplot(x=\"time [s]\", y=metric, hue=\"z\", legend=False,\n",
    "#                     palette=cmap_name, height=7, aspect=7,\n",
    "#                     kind=\"scatter\", data=df_filtered)\n",
    "#     g.fig.colorbar(matplotlib.cm.ScalarMappable(matplotlib.colors.Normalize(vmin=z_offset, vmax=df[\"z\"].max()+z_offset, clip=False), cmap=cmap_name), label='z')\n",
    "# #     g.fig.axes[0].set_xlim(0, 9399*0.025)\n",
    "#     g.fig.tight_layout()\n",
    "#     root = Path(\"refine_lfd_training_plots\")\n",
    "#     root.mkdir(exist_ok=True)\n",
    "#     g.fig.savefig(root / f\"{metric}.png\")\n",
    "#\n",
    "# plot_scans(\"ms_ssim-scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_scans(\"ms_ssim-scaled\")\n",
    "# plot_scans(\"ssim-scaled\")\n",
    "# plot_scans(\"nrmse-scaled\")\n",
    "# plot_scans(\"psnr-scaled\")\n",
    "# plot_scans(\"mse_loss-scaled\")\n",
    "# plot_scans(\"smooth_l1_loss-scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_bins = df.groupby([\"z_bin\", \"pred_nr\"]).mean().reset_index()\n",
    "# df_bins.head()\n",
    "# g = seaborn.catplot(x=\"pred_nr\", y=\"ms_ssim-scaled\", hue=\"pred_nr\",\n",
    "#                 capsize=.2, palette=\"YlGnBu_d\", height=3, aspect=1.0,\n",
    "#                 kind=\"point\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scans_grid(\"ms_ssim-scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
